{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RACIPE_data_import(filename):\n",
    "  Network = pd.read_table(filename[:-13] + '_solution.dat', sep ='\\t', index_col  = False, header = None) \n",
    "  Network_prs= pd.read_csv(filename[:-13] + '.prs', sep ='\\t', index_col  = False) \n",
    "\n",
    "  c = ['Model Number','Stable States','Number of Runs that converged']\n",
    "  p = 'P'\n",
    "  i = 0\n",
    "\n",
    "  while p =='P':\n",
    "    c.append(Network_prs.iloc[i,0][8:])\n",
    "    p = Network_prs.iloc[i+1,0][0]\n",
    "    i = i + 1\n",
    "  Network.columns= c\n",
    "  return Network\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Network_3_T1 = RACIPE_data_import('Network5_trial1_solution.dat')\n",
    "Network_3_T2 = RACIPE_data_import('Network5_trial2_solution.dat')\n",
    "Network_3_T3 = RACIPE_data_import('Network5_trial3_solution.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stable_states(Network_data):\n",
    "    Network_3_SS= pd.DataFrame([[0]]*10)\n",
    "    Network_3_SS.index=['Monostable','Bistable','Tristable','Tetrastable','5 Stable States', '6 Stable States', '7 Stable States', '8 Stable States', '9 Stable States', '10 Stable States']\n",
    "    Network_3_SS.columns = ['Cases']\n",
    "\n",
    "    Network_3_SS.iloc[:,0] = np.array(Network_data.iloc[:,1].value_counts().sort_index())\n",
    "    Network_3_SS\n",
    "\n",
    "    for i in range(0,10):\n",
    "        Network_3_SS.iloc[i,0] = Network_3_SS.iloc[i,0]/(i+1)\n",
    "    return Network_3_SS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Network_3_SS_T1= stable_states(Network_3_T1)\n",
    "Network_3_SS_T2= stable_states(Network_3_T2)\n",
    "Network_3_SS_T3= stable_states(Network_3_T3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SS_summary_table_network3=Network_3_SS_T1.copy()\n",
    "SS_summary_table_network3.loc[:,'Trial 1'] = Network_3_SS_T1.iloc[:,0]\n",
    "SS_summary_table_network3.loc[:,'Trial 2'] = Network_3_SS_T2.iloc[:,0]\n",
    "SS_summary_table_network3.loc[:,'Trial 3'] = Network_3_SS_T3.iloc[:,0]\n",
    "SS_summary_table_network3=SS_summary_table_network3.drop(columns=['Cases'])\n",
    "SS_summary_table_network3=SS_summary_table_network3/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SS_summary_table_network3.loc[:,'Mean'] = SS_summary_table_network3.mean(axis=1)\n",
    "SS_summary_table_network3.loc[:,'Standard Deviation'] = SS_summary_table_network3.std(axis=1)\n",
    "SS_summary_table_network3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SS_summary_table_network3=SS_summary_table_network3.round(2)\n",
    "SS_summary_table_network3.loc[:,'labels'] = SS_summary_table_network3.loc[:,'Mean'].astype(str) + ' ± ' + SS_summary_table_network3.loc[:,'Standard Deviation'].astype(str) + '%'\n",
    "SS_summary_table_network3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 4 A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 10))\n",
    "plt.rcParams['figure.dpi']= 1000\n",
    "colors = sns.color_palette('pastel')[0:10]\n",
    "patches, texts = plt.pie(SS_summary_table_network3.loc[:,'Mean'], labels = SS_summary_table_network3.loc[:,'labels'], colors = colors,\n",
    "                         \n",
    "                         textprops={\"fontsize\":16} )\n",
    "\n",
    "\n",
    "\n",
    "#plt.legend(patches, SS_summary_table_network3.index, loc='upper left' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 10))\n",
    "plt.rcParams['figure.dpi']= 1000\n",
    "colors = sns.color_palette('pastel')[0:10]\n",
    "\n",
    "#patches, texts = plt.pie(SS_summary_table_network3.loc[:,'Mean'], labels = SS_summary_table_network3.loc[:,'labels'], colors = colors)\n",
    "plt.legend(patches, SS_summary_table_network3.index, loc='upper left' )\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EM and SN Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "def standard_scaling(dataframe):\n",
    "    cols = dataframe.columns \n",
    "    return pd.DataFrame(ss.fit_transform(dataframe), columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Network_3_T1.loc[:,'ERa66':] = standard_scaling(Network_3_T1.loc[:,'ERa66':])\n",
    "Network_3_T2.loc[:,'ERa66':] = standard_scaling(Network_3_T2.loc[:,'ERa66':])\n",
    "Network_3_T3.loc[:,'ERa66':] = standard_scaling(Network_3_T3.loc[:,'ERa66':])\n",
    "Network_3_T1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EM_SN_scorer(Network):\n",
    "    Network.loc[:,'SN Score'] = (Network.loc[:,'OCT4'] + Network.loc[:,'LIN28'] - Network.loc[:,'miR145'] - Network.loc[:,'let7'])/4\n",
    "    Network.loc[:,'EM Score'] = (Network.loc[:,'ZEB'] + Network.loc[:,'SLUG'] - Network.loc[:,'miR200'] - Network.loc[:,'CDH1'])/4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EM_SN_scorer(Network_3_T1)\n",
    "EM_SN_scorer(Network_3_T2)\n",
    "EM_SN_scorer(Network_3_T3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Network_3_T1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.75)\n",
    "plt.rcParams['figure.dpi']= 500\n",
    "sns.clustermap(Network_3_T1.loc[:,'ERa66':'OCT4'], metric=\"euclidean\", cmap ='seismic', standard_scale=1, method=\"ward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''sns.set(font_scale=4)\n",
    "sns.clustermap(Network_3_T1.loc[:,'ERa66':'OCT4'], metric=\"euclidean\", cmap ='seismic', standard_scale=1, method=\"ward\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EM_kde_plot(Network, EM_upper , EM_lower ):\n",
    "    plt_1 = plt.figure(figsize=(2, 3))\n",
    "    #sns.set_palette(palette)\n",
    "    sns.displot(Network, x=\"EM Score\", fill=True, bins = 120 ,kde = True, color = 'red')\n",
    "\n",
    "    plt.axvline(x = EM_lower, color = 'black', linestyle = ':')\n",
    "    plt.axvline(x = EM_upper, color = 'black', linestyle = ':')\n",
    "    plt.xlabel('EM Score')\n",
    "    plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SN_kde_plot(Network, SN_upper , SN_lower ):\n",
    "    plt_1 = plt.figure(figsize=(2, 3))\n",
    "    #sns.set_palette(palette)\n",
    "    sns.displot(Network, x=\"SN Score\", fill=True, bins = 120 ,kde = True, color = 'purple')\n",
    "    plt.axvline(x = SN_lower, color = 'r', linestyle = ':')\n",
    "    plt.axvline(x = SN_upper, color = 'r', linestyle = ':')\n",
    "    plt.xlabel('SN Score')\n",
    "    plt.ylabel('Frequency')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EM_SN_classifier(Network, EM_upper, EM_lower, SN_upper, SN_lower):\n",
    "    for i in range(len(Network)):\n",
    "        if Network.loc[i,'EM Score'] >= EM_upper :\n",
    "            Network.loc[i,'EM_Status'] = 'Mesenchymal'\n",
    "\n",
    "        elif Network.loc[i,'EM Score'] < EM_lower :\n",
    "            Network.loc[i,'EM_Status'] = 'Epithelial'\n",
    "        else :\n",
    "            Network.loc[i,'EM_Status'] = 'Hybrid'\n",
    "        \n",
    "        \n",
    "        if Network.loc[i,'SN Score'] >= SN_upper :\n",
    "            Network.loc[i,'Stemness_Status'] = 'Non-Stem-like'\n",
    "\n",
    "        elif Network.loc[i,'SN Score'] < SN_lower :\n",
    "            Network.loc[i,'Stemness_Status'] = 'Non-Stem-like'\n",
    "            \n",
    "        else :\n",
    "            Network.loc[i,'Stemness_Status'] = 'Stem-like'\n",
    "\n",
    "\n",
    "    \n",
    "        if Network.loc[i,'BACH1'] >= 0 :\n",
    "            Network.loc[i,'BACH1_Status'] = 'BACH1_Positive'\n",
    "\n",
    "        elif Network.loc[i,'BACH1'] < 0 :\n",
    "            Network.loc[i,'BACH1_Status'] = 'BACH1_Negative'\n",
    "\n",
    "        \n",
    "        if Network.loc[i,'RKIP'] >= 0 :\n",
    "            Network.loc[i,'RKIP_Status'] = 'RKIP_Positive'\n",
    "\n",
    "        elif Network.loc[i,'RKIP'] < 0 :\n",
    "            Network.loc[i,'RKIP_Status'] = 'RKIP_Negative'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EM_kde_plot(Network, EM_upper , EM_lower ):\n",
    "    plt.figure(figsize=(20, 30))\n",
    "    #sns.set_palette(palette)\n",
    "    sns.displot(Network, x=\"EM Score\", fill=True, bins = 120 ,kde = True, color = 'red')\n",
    "    plt.rcParams['figure.dpi']= 500\n",
    "    plt.axvline(x = EM_lower, color = 'black', linestyle = ':')\n",
    "    plt.axvline(x = EM_upper, color = 'black', linestyle = ':')\n",
    "\n",
    "    plt.xticks(fontsize = 14, fontname='Arial')\n",
    "    plt.yticks(fontsize = 14, fontname='Arial')\n",
    "    plt.xlabel('EM Score',fontsize = 14, fontname='Arial',  fontweight='bold')\n",
    "\n",
    "    plt.ylabel('Frequency',fontsize = 14, fontname='Arial',  fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SN_kde_plot(Network, SN_upper , SN_lower ):\n",
    "    plt.figure(figsize=(20, 30))\n",
    "    plt.rcParams['figure.dpi']= 1000\n",
    "\n",
    "    #sns.set_palette(palette)\n",
    "    sns.displot(Network, x=\"SN Score\", fill=True, bins = 120 ,kde = True, color = 'purple')\n",
    "    plt.axvline(x = SN_lower, color = 'r', linestyle = ':')\n",
    "    plt.axvline(x = SN_upper, color = 'r', linestyle = ':')\n",
    "    #plt.xlabel('EM Score', )\n",
    "    plt.xticks(fontsize = 14, fontname='Arial')\n",
    "    plt.yticks(fontsize = 14, fontname='Arial')\n",
    "    plt.xlabel('SN Score',fontsize = 14, fontname='Arial', fontweight='bold')\n",
    "    plt.ylabel('Frequency', fontsize = 14, fontname='Arial', fontweight='bold')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SN_kde_plot(Network_3_T1, 0.38 , -0.38 )\n",
    "EM_kde_plot(Network_3_T1, 0.64 , -0.24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SN_kde_plot(Network_3_T2, 0.39 , -0.38 )\n",
    "EM_kde_plot(Network_3_T2, 0.63 , -0.26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Network_3_T2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure S3B (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "\n",
    "\n",
    "def BiC(dataframe, n, i):\n",
    "    sk=skew(dataframe.loc[:,i],axis=0,bias=True)\n",
    "    kur=kurtosis(dataframe.loc[:,i],bias=True,axis=0,fisher=True)\n",
    "\n",
    "    ncum=(pow(n-1,2))/((n-2)*(n-3))\n",
    "    bic=(pow(sk,2) + 1)/(kur +3*ncum)\n",
    "    return bic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.rcParams['figure.dpi']= 500\n",
    "\n",
    "# Set the style with blue background and white grid\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "# Figure size and layout\n",
    "fig, axes = plt.subplots(nrows=3, ncols=4, figsize=(11, 7))\n",
    "\n",
    "# Flatten the axes array for easier indexing\n",
    "axes = axes.flatten()\n",
    "plt.rcParams['figure.dpi']= 500\n",
    "# Loop through each column and create histograms with thinner bars\n",
    "#for i, column in enumerate(Network_3_T2.columns[3:15]):\n",
    "#    sns.displot(Network_3_T2[column], ax=axes[i], kde=True )\n",
    "    #axes[i].set_title(f'{column}', fontsize=12)\n",
    "#    axes[i].set_xlabel(' ', fontsize=12)\n",
    "#    axes[i].set_ylabel(' ', fontsize=12)\n",
    "    #axes[i].text(0.05, 0.95, \"BC \" + str(round(BiC(Network_3_T2, 10000, column),2)), transform=axes[i].transAxes, fontsize=0.1, va='top', ha='left')\n",
    "\n",
    "for i, column in enumerate(Network_3_T2.columns[3:15]):\n",
    "    ax = axes[i]\n",
    "    sns.histplot(Network_3_T2[column], ax=ax, kde=True,stat='probability', color='#1284c8')\n",
    "    ax.set_xlabel(column, fontsize=12)\n",
    "    ax.set_ylabel('', fontsize=12)\n",
    "    ax.tick_params(axis='both', labelsize=10)\n",
    "    ax.text(0.05, 0.95, \"BC \" + str(round(BiC(Network_3_T2, 10000, column),2)), transform=axes[i].transAxes, fontsize=12, va='top', ha='left')\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "fig.supxlabel('Z-Normalized Score', weight='bold',fontsize=16,x=0.55, y=0)\n",
    "fig.supylabel('Kernal Density Estimate', weight='bold',fontsize=16,x=-0.0, y=0.55)\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re-indexing based on PC1 coefficients\n",
    "\n",
    "corr_map=Network_3_T2.iloc[:,3:16].corr()\n",
    "corr_map_reindex=corr_map.reindex(['ZEB', 'LIN28', 'SLUG', 'ERa36', 'OCT4', 'BACH1', 'RKIP', 'SNAIL',\n",
    "       'ERa66', 'miR145', 'let7', 'miR200', 'CDH1'])\n",
    "corr_map=corr_map_reindex.T\n",
    "corr_map_reindex=corr_map.reindex(['ZEB', 'LIN28', 'SLUG', 'ERa36', 'OCT4', 'BACH1', 'RKIP', 'SNAIL',\n",
    "       'ERa66', 'miR145', 'let7', 'miR200', 'CDH1'])\n",
    "corr_map_reindex\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 3Bii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating mask\n",
    "plt.rcParams['figure.dpi']= 500\n",
    "mask = np.triu(np.ones_like(corr_map_reindex, dtype=bool),k=0)\n",
    "for i in range(len(mask)):\n",
    "                mask[i][i]= False\n",
    "sns.set_style(\"white\")\n",
    "# plotting a triangle correlation heatmap\n",
    "dataplot = sns.heatmap(corr_map_reindex,cmap='coolwarm', annot=False, mask=mask,square=True, linecolor= 'white',linewidths=0.5,cbar_kws={'label': 'Spearman Coefficient (ρ)'})\n",
    "cbar = dataplot.collections[0].colorbar\n",
    "cbar.set_label('Spearman Coefficient (ρ)', labelpad=17)\n",
    "\n",
    "# displaying heatmap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Network_3_T2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components =10)\n",
    "pca.fit(Network_3_T2.loc[:,'ERa66':'OCT4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_data = pd.DataFrame(pca.components_[0:2],columns=Network_3_T2.loc[:,'ERa66':'OCT4'].columns).T.sort_values(by=0)\n",
    "PCA_data.columns = ['PC1','PC2']\n",
    "PCA_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Network_3_T2.iloc[:,3:16].corr(method='spearman')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking p-value for each spearman co-relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix, p_values = spearmanr(Network_3_T2.iloc[:,3:16])\n",
    "p_val_matrix = pd.DataFrame(p_values, columns =Network_3_T2.iloc[:,3:16].columns, index = Network_3_T2.iloc[:,3:16].columns )\n",
    "p_val_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 4C (i) & (ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SN_kde_plot(Network_3_T3, 0.38 , -0.37 )\n",
    "EM_kde_plot(Network_3_T3, 0.63 , -0.25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 4 D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "#sns.set_style(\"whitegrid\")\n",
    "#plt.grid(False)\n",
    "plt.rcParams['figure.dpi']= 1000\n",
    "plo = sns.scatterplot(data=Network_3_T1, x=\"EM Score\", y=\"SN Score\", s = 2, color='Black' )\n",
    "plt.xlabel(\"EM Score\", fontweight='bold', size=17, fontname='Arial')\n",
    "plt.ylabel('SN Score',  fontweight='bold' , size=17 , fontname='Arial')\n",
    "plt.xticks(size=15)\n",
    "plt.yticks(size=15)\n",
    "#plo.plot(grid = False)\n",
    "plt.axhline(y = -0.38, color = 'r', linestyle = ':')\n",
    "plt.axhline(y = 0.38, color = 'r', linestyle = ':')\n",
    "plt.axvline(x = -0.24, color = 'r', linestyle = ':')\n",
    "plt.axvline(x = 0.64, color = 'r', linestyle = ':')\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spearman Coefficient EM vs SN Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearmanr(Network_3_T1.loc[:,'EM Score'],Network_3_T1.loc[:,'SN Score'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Network_3_T2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SN_kde_plot(Network_3_T1, 0.38 , -0.38 )\n",
    "EM_kde_plot(Network_3_T1, 0.64 , -0.24)\n",
    "\n",
    "SN_kde_plot(Network_3_T2, 0.39 , -0.38 )\n",
    "EM_kde_plot(Network_3_T2, 0.63 , -0.26)\n",
    "\n",
    "SN_kde_plot(Network_3_T3, 0.38 , -0.37 )\n",
    "EM_kde_plot(Network_3_T3, 0.63 , -0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EM_SN_classifier(Network_3_T1, 0.63 , -0.26, 0.39, -0.38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EM_SN_classifier(Network_3_T2, 0.63 , -0.26, 0.39 , -0.38 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EM_SN_classifier(Network_3_T3, 0.63, -0.25, 0.38 ,-0.37 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Network_3_T3.loc[:,'Stemness_Status'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 4 E (i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summari(Network1,Network2,Network3,given, gene, status):\n",
    "    dat1=pd.DataFrame(index=['Non-Stem-like','Stem-like'], columns=['Trial 1','Trial 2','Trial 3'])\n",
    "    dat1.loc[:, 'Trial 1']=((Network1[Network1.loc[:, gene +'_Status']==given]).loc[:, status].value_counts().sort_index())/sum((Network1[Network1.loc[:,  gene +'_Status']==given]).loc[:, status].value_counts().sort_index())\n",
    "    dat1.loc[:,'Trial 2']= ((Network2[Network2.loc[:, gene+'_Status']==given]).loc[:, status].value_counts().sort_index())/sum((Network2[Network2.loc[:,  gene +'_Status']==given]).loc[:, status].value_counts().sort_index())\n",
    "    dat1.loc[:,'Trial 3']= ((Network3[Network3.loc[:, gene+'_Status']==given]).loc[:, status].value_counts().sort_index())/sum((Network3[Network3.loc[:,  gene +'_Status']==given]).loc[:, status].value_counts().sort_index())\n",
    "    dat1.loc[:,'Std']=dat1.loc[:,['Trial 1','Trial 2','Trial 3']].std(axis=1)\n",
    "    dat1.loc[:,'Mean']=dat1.loc[:,['Trial 1','Trial 2','Trial 3']].mean(axis=1)\n",
    "    dat1.loc[:,'Probabilty Given '+ given] = round(dat1.loc[:,'Mean']*100,2).astype(str) + ' ± ' + round(dat1.loc[:,'Std']*100,2).astype(str) + '%'\n",
    "    return dat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summari_rev(Network1,Network2,Network3,given, gene, status):\n",
    "    dat1=pd.DataFrame(index=['BACH1_Positive','BACH1_Negative'], columns=['Trial 1','Trial 2','Trial 3'])\n",
    "    dat1.loc[:, 'Trial 1']=((Network1[Network1.loc[:, gene +'_Status']==given]).loc[:, status].value_counts().sort_index())/sum((Network1[Network1.loc[:,  gene +'_Status']==given]).loc[:, status].value_counts().sort_index())\n",
    "    dat1.loc[:,'Trial 2']= ((Network2[Network2.loc[:, gene+'_Status']==given]).loc[:, status].value_counts().sort_index())/sum((Network2[Network2.loc[:,  gene +'_Status']==given]).loc[:, status].value_counts().sort_index())\n",
    "    dat1.loc[:,'Trial 3']= ((Network3[Network3.loc[:, gene+'_Status']==given]).loc[:, status].value_counts().sort_index())/sum((Network3[Network3.loc[:,  gene +'_Status']==given]).loc[:, status].value_counts().sort_index())\n",
    "    dat1.loc[:,'Std']=dat1.loc[:,['Trial 1','Trial 2','Trial 3']].std(axis=1)\n",
    "    dat1.loc[:,'Mean']=dat1.loc[:,['Trial 1','Trial 2','Trial 3']].mean(axis=1)\n",
    "    dat1.loc[:,'Probabilty Given '+ given] = round(dat1.loc[:,'Mean']*100,2).astype(str) + ' ± ' + round(dat1.loc[:,'Std']*100,2).astype(str) + '%'\n",
    "    return dat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Network_3_T3[Network_3_T3.loc[:, 'EM_Status']=='Epithelial']).loc[:, 'BACH1_Status'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Network_3_T2[Network_3_T2.loc[:, 'EM_Status']=='Epithelial']).loc[:, 'BACH1_Status'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Network_3_T1[Network_3_T1.loc[:, 'EM_Status']=='Epithelial']).loc[:, 'BACH1_Status'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summari_rev(Network_3_T3,Network_3_T2,Network_3_T1, 'Epithelial', 'EM', 'BACH1_Status').loc[:,'Probabilty Given Epithelial']\n",
    "'''conditional=pd.DataFrame( index=['BACH1_Positive','BACH1_Negative'], columns=['Given Epithelial'])\n",
    "conditional.loc[:,'Given Epithelial']=summari_rev(Network_3_T3,Network_3_T2,Network_3_T1, 'Epithelial', 'EM', 'BACH1_Status').loc[:,'Probabilty Given Epithelial']\n",
    "conditional.loc[:,'Given Hybrid']=summari_rev(Network_3_T3,Network_3_T2,Network_3_T1, 'Hybrid', 'EM', 'BACH1_Status').loc[:,'Probabilty Given Epithelial']\n",
    "conditional.loc[:,'Given Epithelial']=summari_rev(Network_3_T3,Network_3_T2,Network_3_T1, 'Epithelial', 'EM', 'BACH1_Status').loc[:,'Probabilty Given Epithelial']\n",
    "conditional.loc[:,'Given Epithelial']=summari_rev(Network_3_T3,Network_3_T2,Network_3_T1, 'Epithelial', 'EM', 'BACH1_Status').loc[:,'Probabilty Given Epithelial']\n",
    "#conditional.loc[:,'Given BACH1 Negative']=summari_rev(Network_3_T3,Network_3_T2,Network_3_T1, 'BACH1_Negative', 'BACH1', 'Stemness_Status').loc[:,'Probabilty Given BACH1_Negative']\n",
    "#conditional.loc[:,'Given RKIP Positive']=summari_rev(Network_3_T3,Network_3_T2,Network_3_T1, 'RKIP_Positive', 'RKIP', 'Stemness_Status').loc[:,'Probabilty Given RKIP_Positive']\n",
    "#conditional.loc[:,'Given RKIP Negative']=summari_rev(Network_3_T3,Network_3_T2,Network_3_T1, 'RKIP_Negative', 'RKIP', 'Stemness_Status').loc[:,'Probabilty Given RKIP_Negative']\n",
    "conditional.T'''\n",
    "#(Network_3_T1[Network_3_T1.loc[:, 'RKIP_Status']=='RKIP_Negative']).value_counts().sort_index()\n",
    "'''conditional=pd.DataFrame( index=['Non-Stem-like','Stem-like'])\n",
    "conditional.loc[:,'Given BACH1 Positive']=summari(Network_3_T3,Network_3_T2,Network_3_T1, 'BACH1_Positive', 'BACH1', 'Stemness_Status').loc[:,'Probabilty Given BACH1_Positive']\n",
    "conditional.loc[:,'Given BACH1 Negative']=summari(Network_3_T3,Network_3_T2,Network_3_T1, 'BACH1_Negative', 'BACH1', 'Stemness_Status').loc[:,'Probabilty Given BACH1_Negative']\n",
    "conditional.loc[:,'Given RKIP Positive']=summari(Network_3_T3,Network_3_T2,Network_3_T1, 'RKIP_Positive', 'RKIP', 'Stemness_Status').loc[:,'Probabilty Given RKIP_Positive']\n",
    "conditional.loc[:,'Given RKIP Negative']=summari(Network_3_T3,Network_3_T2,Network_3_T1, 'RKIP_Negative', 'RKIP', 'Stemness_Status').loc[:,'Probabilty Given RKIP_Negative']\n",
    "conditional.T'''\n",
    "'''conditional=pd.DataFrame( index=['Epithelial','Hybrid','Mesenchymal'])\n",
    "conditional.loc[:,'Given BACH1 Positive']=summari(Network_3_T3,Network_3_T2,Network_3_T1, 'BACH1_Positive', 'BACH1', 'EM_Status').loc[:,'Probabilty Given BACH1_Positive']\n",
    "conditional.loc[:,'Given BACH1 Negative']=summari(Network_3_T3,Network_3_T2,Network_3_T1, 'BACH1_Negative', 'BACH1', 'EM_Status').loc[:,'Probabilty Given BACH1_Negative']\n",
    "conditional.loc[:,'Given RKIP Positive']=summari(Network_3_T3,Network_3_T2,Network_3_T1, 'RKIP_Positive', 'RKIP', 'EM_Status').loc[:,'Probabilty Given RKIP_Positive']\n",
    "conditional.loc[:,'Given RKIP Negative']=summari(Network_3_T3,Network_3_T2,Network_3_T1, 'RKIP_Negative', 'RKIP', 'EM_Status').loc[:,'Probabilty Given RKIP_Negative']\n",
    "conditional.T'''\n",
    "'''summari(Network_3_T3,Network_3_T2,Network_3_T1, 'BACH1_Negative', 'BACH1', 'Stemness_Status')\n",
    "summari(Network_3_T3,Network_3_T2,Network_3_T1, 'BACH1_Positive', 'BACH1', 'Stemness_Status')\n",
    "summari(Network_3_T3,Network_3_T2,Network_3_T1, 'RKIP_Positive', 'RKIP', 'Stemness_Status')\n",
    "summari(Network_3_T3,Network_3_T2,Network_3_T1, 'RKIP_Negative', 'RKIP', 'Stemness_Status')'''\n",
    "'''conditional=pd.DataFrame( index=['Non-Stem-like','Stem-like',])\n",
    "conditional.loc[:,'Given BACH1 Positive']=summari(Network_3_T3,Network_3_T2,Network_3_T1, 'BACH1_Positive', 'BACH1', 'Stemness_Status').loc[:,'Probabilty Given BACH1_Positive']\n",
    "conditional.loc[:,'Given BACH1 Negative']=summari(Network_3_T3,Network_3_T2,Network_3_T1, 'BACH1_Negative', 'BACH1', 'Stemness_Status').loc[:,'Probabilty Given BACH1_Negative']\n",
    "conditional.loc[:,'Given RKIP Positive']=summari(Network_3_T3,Network_3_T2,Network_3_T1, 'RKIP_Positive', 'RKIP', 'Stemness_Status').loc[:,'Probabilty Given RKIP_Positive']\n",
    "conditional.loc[:,'Given RKIP Negative']=summari(Network_3_T3,Network_3_T2,Network_3_T1, 'RKIP_Negative', 'RKIP', 'Stemness_Status').loc[:,'Probabilty Given RKIP_Negative']\n",
    "conditional'''\n",
    "#summari(Network_3_T3,Network_3_T2,Network_3_T1, 'RKIP_Negative', 'RKIP', 'EM_Status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summar(Network1,Network2,Network3, case1, given, given_col):\n",
    "    cond=pd.DataFrame()\n",
    "    cond.loc[:,'Trial 1']=((Network1[Network1.loc[:, given_col]==given]).loc[:,case1]>0).value_counts().sort_index(ascending=False) /sum(((Network1[Network1.loc[:,'Stemness_Status']==given]).loc[:,case1]>0).value_counts().sort_index(ascending=False))\n",
    "    cond.loc[:,'Trial 2']=((Network2[Network2.loc[:,given_col ]==given]).loc[:,case1]>0).value_counts().sort_index(ascending=False)/sum(((Network2[Network2.loc[:,'Stemness_Status']==given]).loc[:,case1]>0).value_counts().sort_index(ascending=False))\n",
    "    cond.loc[:,'Trial 3']=((Network3[Network3.loc[:,given_col]==given]).loc[:,case1]>0).value_counts().sort_index(ascending=False)/sum(((Network3[Network3.loc[:,'Stemness_Status']==given]).loc[:,case1]>0).value_counts().sort_index(ascending=False))\n",
    "    cond.index=[case1 +'+ve', case1 + '-ve']\n",
    "    cond.loc[:,'Mean'] = cond.iloc[:,0:3].mean(axis=1)\n",
    "    cond.loc[:,'Standard Deviation'] = cond.iloc[:,0:3].std(axis=1)/cond.loc[:,'Mean']\n",
    "    cond = cond*100\n",
    "    cond=cond.round(2)\n",
    "    cond.loc[:,'Probabilty Given '  + given] = cond.loc[:,'Mean'].astype(str) + ' ± ' + cond.loc[:,'Standard Deviation'].astype(str) + '%'\n",
    "    return cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Network_3_T3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summar(Network_3_T3,Network_3_T2,Network_3_T1, 'BACH1' ,'Non-Stem-like','Stemness_Status' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summar(Network_3_T3,Network_3_T2,Network_3_T1, 'BACH1' ,'Stem-like' ,'Stemness_Status' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summar(Network_3_T3,Network_3_T2,Network_3_T1, 'RKIP' ,'Non-Stem-like' ,'Stemness_Status' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summar(Network_3_T3,Network_3_T2,Network_3_T1, 'RKIP' ,'Stem-like','Stemness_Status'  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summar(Network_3_T3,Network_3_T2,Network_3_T1, 'BACH1' ,'Stem-like' ,'Stemness_Status' ).loc['BACH1+ve','Probabilty Given Stem-like']\n",
    "conditional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([[0]*2]*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 4E (ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditional=pd.DataFrame([[0]*2]*4, index=['BACH1+ve','BACH1-ve','RKIP+ve','RKIP-ve'])\n",
    "conditional.columns=['Stem-like','Non-Stem-like']\n",
    "conditional.loc['BACH1+ve','Stem-like',]=summar(Network_3_T3,Network_3_T2,Network_3_T1, 'BACH1' ,'Stem-like' ,'Stemness_Status' ).loc['BACH1+ve','Probabilty Given Stem-like']\n",
    "conditional.loc['BACH1+ve','Non-Stem-like']=summar(Network_3_T3,Network_3_T2,Network_3_T1, 'BACH1' ,'Non-Stem-like','Stemness_Status'  ).loc['BACH1+ve','Probabilty Given Non-Stem-like']\n",
    "conditional.loc['RKIP+ve','Stem-like']=summar(Network_3_T3,Network_3_T2,Network_3_T1, 'RKIP' ,'Stem-like','Stemness_Status'  ).loc['RKIP+ve','Probabilty Given Stem-like']\n",
    "conditional.loc['RKIP+ve','Non-Stem-like']=summar(Network_3_T3,Network_3_T2,Network_3_T1, 'RKIP' ,'Non-Stem-like' ,'Stemness_Status' ).loc['RKIP+ve','Probabilty Given Non-Stem-like']\n",
    "conditional.loc['BACH1-ve','Stem-like']=summar(Network_3_T3,Network_3_T2,Network_3_T1, 'BACH1' ,'Stem-like','Stemness_Status'  ).loc['BACH1-ve','Probabilty Given Stem-like']\n",
    "conditional.loc['BACH1-ve','Non-Stem-like']=summar(Network_3_T3,Network_3_T2,Network_3_T1, 'BACH1' ,'Non-Stem-like','Stemness_Status'  ).loc['BACH1-ve','Probabilty Given Non-Stem-like']\n",
    "conditional.loc['RKIP-ve','Stem-like'] = summar(Network_3_T3,Network_3_T2,Network_3_T1, 'RKIP' ,'Stem-like','Stemness_Status'  ).loc['RKIP-ve','Probabilty Given Stem-like']\n",
    "conditional.loc['RKIP-ve','Non-Stem-like']=summar(Network_3_T3,Network_3_T2,Network_3_T1, 'RKIP' ,'Non-Stem-like','Stemness_Status'  ).loc['RKIP-ve','Probabilty Given Non-Stem-like']\n",
    "conditional.columns=['Given Stem-like','Given Non-Stem-like']\n",
    "conditional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''conditional=pd.DataFrame([[0]*2]*4, columns=['Stem-like','Non-Stem-like'])\n",
    "conditional.index=['BACH1+ve', 'BACH1-ve', 'RKIP+ve', 'RKIP-ve']\n",
    "conditional.loc['BACH1+ve','Stem-like']=summar(Network_3_T3,Network_3_T2,Network_3_T1, 'BACH1' ,'Stem-like' ).loc['BACH1+ve','Probabilty Given Stem-like']\n",
    "conditional.loc['BACH1+ve','Non-Stem-like']=summar(Network_3_T3,Network_3_T2,Network_3_T1, 'BACH1' ,'Non-Stem-like' ).loc['BACH1+ve','Probabilty Given Non-Stem-like']\n",
    "conditional.loc['RKIP+ve','Stem-like']=summar(Network_3_T3,Network_3_T2,Network_3_T1, 'RKIP' ,'Stem-like' ).loc['RKIP+ve','Probabilty Given Stem-like']\n",
    "conditional.loc['RKIP+ve','Non-Stem-like']=summar(Network_3_T3,Network_3_T2,Network_3_T1, 'RKIP' ,'Non-Stem-like' ).loc['RKIP+ve','Probabilty Given Non-Stem-like']\n",
    "conditional.loc['BACH1-ve','Stem-like']=summar(Network_3_T3,Network_3_T2,Network_3_T1, 'BACH1' ,'Stem-like' ).loc['BACH1-ve','Probabilty Given Stem-like']\n",
    "conditional.loc['BACH1-ve','Non-Stem-like']=summar(Network_3_T3,Network_3_T2,Network_3_T1, 'BACH1' ,'Non-Stem-like' ).loc['BACH1-ve','Probabilty Given Non-Stem-like']\n",
    "conditional.loc['RKIP-ve','Stem-like']=summar(Network_3_T3,Network_3_T2,Network_3_T1, 'RKIP' ,'Stem-like' ).loc['RKIP-ve','Probabilty Given Stem-like']\n",
    "conditional.loc['RKIP-ve','Non-Stem-like']=summar(Network_3_T3,Network_3_T2,Network_3_T1, 'RKIP' ,'Non-Stem-like' ).loc['RKIP-ve','Probabilty Given Non-Stem-like']\n",
    "conditional.columns=['Given Stem-like','Given Non-Stem-like']\n",
    "conditional'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_EM(Network1,Network2,Network3, case1, given):\n",
    "    cond=pd.DataFrame()\n",
    "    cond.loc[:,'Trial 1']=((Network1[Network1.loc[:,'EM_Status']==given]).loc[:,case1]>0).value_counts().sort_index(ascending=False)/sum(((Network1[Network1.loc[:,'EM_Status']==given]).loc[:,case1]>0).value_counts().sort_index(ascending=False))\n",
    "    cond.loc[:,'Trial 2']=((Network2[Network2.loc[:,'EM_Status']==given]).loc[:,case1]>0).value_counts().sort_index(ascending=False)/sum(((Network2[Network2.loc[:,'EM_Status']==given]).loc[:,case1]>0).value_counts().sort_index(ascending=False))\n",
    "    cond.loc[:,'Trial 3']=((Network3[Network3.loc[:,'EM_Status']==given]).loc[:,case1]>0).value_counts().sort_index(ascending=False)/sum(((Network3[Network3.loc[:,'EM_Status']==given]).loc[:,case1]>0).value_counts().sort_index(ascending=False))\n",
    "    cond.index=[case1 +'+ve', case1 + '-ve']\n",
    "    cond.loc[:,'Mean'] = cond.iloc[:,0:3].mean(axis=1)\n",
    "    cond.loc[:,'Standard Deviation'] = cond.iloc[:,0:3].std(axis=1)/cond.loc[:,'Mean']\n",
    "    cond = cond*100\n",
    "    cond=cond.round(2)\n",
    "    cond.loc[:,'Probabilty Given '  + given] = cond.loc[:,'Mean'].astype(str) + ' ± ' + cond.loc[:,'Standard Deviation'].astype(str) + '%'\n",
    "    return cond\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_EM(Network_3_T3,Network_3_T2,Network_3_T1, 'RKIP' ,'Epithelial' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_EM(Network_3_T3,Network_3_T2,Network_3_T1, 'BACH1' ,'Mesenchymal' )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 4E (ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditional_EM=pd.DataFrame([[0]*3]*4)\n",
    "conditional_EM.columns=['Epithelial','Hybrid','Mesenchymal']\n",
    "conditional_EM.index=['BACH1+ve', 'BACH1-ve', 'RKIP+ve', 'RKIP-ve']\n",
    "conditional_EM.loc['BACH1+ve','Epithelial'] = summary_EM(Network_3_T3,Network_3_T2,Network_3_T1, 'BACH1' ,'Epithelial' ).loc['BACH1+ve','Probabilty Given Epithelial']\n",
    "conditional_EM.loc['BACH1+ve','Hybrid']=summary_EM(Network_3_T3,Network_3_T2,Network_3_T1, 'BACH1' ,'Hybrid' ).loc['BACH1+ve','Probabilty Given Hybrid']\n",
    "conditional_EM.loc['BACH1+ve','Mesenchymal']=summary_EM(Network_3_T3,Network_3_T2,Network_3_T1, 'BACH1' ,'Mesenchymal' ).loc['BACH1+ve','Probabilty Given Mesenchymal']\n",
    "conditional_EM.loc['BACH1-ve','Epithelial']=summary_EM(Network_3_T3,Network_3_T2,Network_3_T1, 'BACH1' ,'Epithelial' ).loc['BACH1-ve','Probabilty Given Epithelial']\n",
    "conditional_EM.loc['BACH1-ve','Hybrid']=summary_EM(Network_3_T3,Network_3_T2,Network_3_T1, 'BACH1' ,'Hybrid' ).loc['BACH1-ve','Probabilty Given Hybrid']\n",
    "conditional_EM.loc['BACH1-ve','Mesenchymal']=summary_EM(Network_3_T3,Network_3_T2,Network_3_T1, 'BACH1' ,'Mesenchymal' ).loc['BACH1-ve','Probabilty Given Mesenchymal']\n",
    "conditional_EM.loc['RKIP+ve','Epithelial']=summary_EM(Network_3_T3,Network_3_T2,Network_3_T1, 'RKIP' ,'Epithelial' ).loc['RKIP+ve','Probabilty Given Epithelial']\n",
    "conditional_EM.loc['RKIP+ve','Hybrid']=summary_EM(Network_3_T3,Network_3_T2,Network_3_T1, 'RKIP' ,'Hybrid' ).loc['RKIP+ve','Probabilty Given Hybrid']\n",
    "conditional_EM.loc['RKIP+ve','Mesenchymal']=summary_EM(Network_3_T3,Network_3_T2,Network_3_T1, 'RKIP' ,'Mesenchymal' ).loc['RKIP+ve','Probabilty Given Mesenchymal']\n",
    "conditional_EM.loc['RKIP-ve','Epithelial']=summary_EM(Network_3_T3,Network_3_T2,Network_3_T1, 'RKIP' ,'Epithelial' ).loc['RKIP-ve','Probabilty Given Epithelial']\n",
    "conditional_EM.loc['RKIP-ve','Hybrid']=summary_EM(Network_3_T3,Network_3_T2,Network_3_T1, 'RKIP' ,'Hybrid' ).loc['RKIP-ve','Probabilty Given Hybrid']\n",
    "conditional_EM.loc['RKIP-ve','Mesenchymal']=summary_EM(Network_3_T3,Network_3_T2,Network_3_T1, 'RKIP' ,'Mesenchymal' ).loc['RKIP-ve','Probabilty Given Mesenchymal']\n",
    "conditional_EM.columns=['Given Epithelial','Given Hybrid','Given Mesenchymal']\n",
    "conditional_EM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''RKIP_summary_EM = pd.DataFrame([[0]]*3)\n",
    "RKIP_summary_EM.loc[:,'Net3_T1']=np.array(cross(Network_3_T1, 'EM' , 'RKIP').iloc[:,-1])\n",
    "RKIP_summary_EM.loc[:,'Net3_T2']=np.array(cross(Network_3_T2, 'EM' , 'RKIP').iloc[:,-1])\n",
    "RKIP_summary_EM.loc[:,'Net3_T3']=np.array(cross(Network_3_T3, 'EM' , 'RKIP').iloc[:,-1])\n",
    "RKIP_summary_EM= RKIP_summary_EM.loc[:,'Net3_T1':]\n",
    "RKIP_summary_EM.index = cross(Network_3_T1, 'EM' , 'RKIP').iloc[:,-1].index'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''RKIP_summary_EM.loc[:,'Mean'] =RKIP_summary_EM.loc[:, ['Net3_T1','Net3_T2','Net3_T3']].T.describe().loc['mean',:]\n",
    "RKIP_summary_EM.loc[:,'Std'] =RKIP_summary_EM.loc[:, ['Net3_T1','Net3_T2','Net3_T3']].T.describe().loc['std',:]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''RKIP_summary_EM.loc[:,'printable']=round(RKIP_summary_EM.loc[:,'Mean'],2).astype(str) + ' ± ' + round(RKIP_summary_EM.loc[:,'Std'],2).astype(str) \n",
    "RKIP_summary_EM'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''RKIP_summary_EM'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''BACH1_summary_EM = pd.DataFrame([[0]]*3)\n",
    "BACH1_summary_EM.loc[:,'Net3_T1']=np.array(cross(Network_3_T1, 'EM' , 'BACH1').iloc[:,-1])\n",
    "BACH1_summary_EM.loc[:,'Net3_T2']=np.array(cross(Network_3_T2, 'EM' , 'BACH1').iloc[:,-1])\n",
    "BACH1_summary_EM.loc[:,'Net3_T3']=np.array(cross(Network_3_T3, 'EM' , 'BACH1').iloc[:,-1])\n",
    "BACH1_summary_EM= BACH1_summary_EM.loc[:,'Net3_T1':]\n",
    "BACH1_summary_EM.index = cross(Network_3_T1, 'EM' , 'BACH1').iloc[:,-1].index'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''BACH1_summary_EM.loc[:,'Mean'] =BACH1_summary_EM.loc[:, ['Net3_T1','Net3_T2','Net3_T3']].T.describe().loc['mean',:]\n",
    "BACH1_summary_EM.loc[:,'Std'] =BACH1_summary_EM.loc[:, ['Net3_T1','Net3_T2','Net3_T3']].T.describe().loc['std',:]\n",
    "BACH1_summary_EM'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''BACH1_summary_EM'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Network_3_T3.loc[:,['PC1','PC2','PC3','PC4','PC5','PC6','PC7','PC8','PC9','PC10']]=pca.fit_transform(Network_3_T3.loc[:,'ERa66':'OCT4'])\n",
    "Network_3_T3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hue_scatterplot(dataframe , x, y , x_label, y_label, hue, colors='viridis', vmax = 3, vmin =-3):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    #plt.rcParams['figure.dpi']= 1000\n",
    "    #plt.title('Network 1')\n",
    "    #ax.figsize = (19, 8)\n",
    "    \n",
    "    #fig, ax = plt.subplots()\n",
    "    plo = plt.scatter(data= dataframe, x=x, y=y, s = 0.5,  c = dataframe.loc[:,hue] , cmap = colors, vmax = vmax, vmin =vmin)\n",
    "    plt.xlabel(x_label, fontsize=17)\n",
    "    plt.ylabel(y_label,  fontsize=17)\n",
    "    plt.xticks(size=17)\n",
    "    plt.yticks(size=17)\n",
    "\n",
    "    plt.legend('')\n",
    "    \n",
    "    \n",
    "    cbar  = plt.colorbar(plo)\n",
    "    cbar.ax.tick_params(labelsize=17)\n",
    "    cbar.set_label(hue, rotation=270, size = 17, labelpad= 14)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 3E (i) & (ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Explained_vaience = pd.DataFrame(pca.explained_variance_ratio_,  index = ['PC1','PC2','PC3','PC4','PC5','PC6','PC7','PC8','PC9','PC10'])*100\n",
    "Explained_vaience.columns = ['Pecentage Explained Vaience']\n",
    "Explained_vaience"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 3 E (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hue_scatterplot(Network_3_T3, 'PC1', 'PC2','PC1 (48.8% of the Total Varience )', 'PC2 (19.5% of the Total Varience )', hue='RKIP' ,  colors='seismic', vmax = 3, vmin =-3)\n",
    "plt.title(\"RACIPE solutions shaded based on RKIP expression\", size=19, fontname='Arial', fontweight='bold')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hue_scatterplot(Network_3_T3, 'PC1', 'PC2', 'PC1 (48.8% of the Total Varience )', 'PC2 (19.5% of the Total Varience )', hue='BACH1' ,  colors='seismic', vmax = 3, vmin =-3)\n",
    "plt.title(\"RACIPE solutions shaded based on BACH1 expression\", size=19, fontname='Arial', fontweight='bold')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 3 B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Topo_Network_5 = pd.read_csv('Network5_trial2.topo', sep='\\t')\n",
    "Topo_Network_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Topo_adj(dp):\n",
    "    n=len(set(dp['Source']))\n",
    "    adj = pd.DataFrame([[0]*n]*n)\n",
    "    adj.columns=set(dp.loc[:,'Source'])\n",
    "    adj.index=set(dp.loc[:,'Source'])\n",
    "    for i in range(len(dp)):\n",
    "        if dp.iloc[i,2] == 1:\n",
    "            adj.loc[dp.iloc[i,0] , dp.iloc[i,1] ] = 1\n",
    "        elif dp.iloc[i,2] == 2:\n",
    "            adj.loc[dp.iloc[i,0] , dp.iloc[i,1] ] = -1\n",
    "\n",
    "    return adj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Topo_adj(Topo_Network_5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 3B Adjacency Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inf = influence(Topo_Network_5, 10)\n",
    "sns.set(font_scale=1.1)\n",
    "plt.rcParams['figure.dpi']= 1000\n",
    "\n",
    "#plt.xlabel(fontsize=16);\n",
    "#plt.ylabel(fontsize=16);\n",
    "#plt.title('Sales Data', fontsize=20)\n",
    "with plt.style.context({\n",
    "                        'xtick.labelsize':16,\n",
    "                        'ytick.labelsize':16}):\n",
    "        sns.clustermap(Topo_adj(Topo_Network_5), annot = True, cmap ='coolwarm',\n",
    "                       linecolor ='black', linewidths = 1)\n",
    "plt.tick_params(axis='both', which='major', labelsize=13)\n",
    "#plt.ylabel('Source', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def influence(dp, j):\n",
    "    n=len(set(dp['Source']))\n",
    "    infl = pd.DataFrame([[0]*n]*n)\n",
    "    infl.columns=set(dp.loc[:,'Source'])\n",
    "    infl.index=set(dp.loc[:,'Source'])\n",
    "    adj = Topo_adj(dp)\n",
    "\n",
    "    maxi = abs(adj)\n",
    "    pr = adj\n",
    "    mr = abs(adj)\n",
    "    infl = adj\n",
    "    for i in range(1, j):\n",
    "        pr=adj@pr\n",
    "        mr = maxi@mr\n",
    "        qwe = pr/mr\n",
    "\n",
    "        infl = infl + qwe.replace(np.nan, 0)\n",
    "        \n",
    "        \n",
    "\n",
    "    infl  = infl/j\n",
    "    infl=infl.round(2)\n",
    "    return infl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,8))\n",
    "\n",
    "plt.rcParams['figure.dpi']= 1000\n",
    "with plt.style.context({\n",
    "                        'xtick.labelsize':16,\n",
    "                        'ytick.labelsize':16}):\n",
    "        sns.clustermap(influence(Topo_Network_5, 8), annot = True, cmap ='coolwarm', vmax = 1, vmin =-1,\n",
    "                       linecolor ='black', linewidths = 1)\n",
    "        \n",
    "plt.tick_params(axis='both', which='major', labelsize=13)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 3 C Pathlength 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,8))\n",
    "\n",
    "plt.rcParams['figure.dpi']= 1000\n",
    "with plt.style.context({\n",
    "                        'xtick.labelsize':16,\n",
    "                        'ytick.labelsize':16}):\n",
    "        sns.clustermap(influence(Topo_Network_5, 8),  cmap ='coolwarm', vmax = 1, vmin =-1,\n",
    "                       linecolor ='black', linewidths = 1)\n",
    "        \n",
    "plt.tick_params(axis='both', which='major', labelsize=13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tup=influence(Topo_Network_5, 8).sort_values(by='miR200', ascending=True)\n",
    "tupi=tup.T.sort_values(by='miR200', ascending=True)\n",
    "tupi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''plt.figure(figsize=(20,20))\n",
    "sns.heatmap(tupi, linewidths = 1,  cmap=\"coolwarm\", square = True, fmt=\"\",vmax = 0.8, vmin =-0.8, annot = False\n",
    "            ,cbar_kws={'orientation': 'horizontal', 'pad' : 0.13, 'aspect': 40}, annot_kws={'size': 15} )\n",
    "plt.tick_params(axis='both', which='major', labelsize=16)'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifying Teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Team1 = []\n",
    "Team2 = []\n",
    "infl = influence(Topo_Network_5, 8)\n",
    "for i in infl.index:\n",
    "    if infl.loc[i,'miR200'] >= 0:\n",
    "        Team1.append(i)\n",
    "    elif infl.loc[i,'miR200'] <= 0:\n",
    "        Team2.append(i) \n",
    "\n",
    "print(Team1)\n",
    "print(Team2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TeamScores = pd.DataFrame(0, columns = [0,1], index = [0,1] )\n",
    "\n",
    "teams = [Team1, Team2]\n",
    "\n",
    "for t1 in range(len(teams)):\n",
    "    for t2 in range(len(teams)):\n",
    "        Tsc= 0 \n",
    "        count = 0\n",
    "        #print(teams[t1])\n",
    "        for i in teams[t1]:\n",
    "            for j in teams[t2]:\n",
    "                 Tsc += tupi.loc[i,j]\n",
    "                 count +=1\n",
    "                 #print(t1,t2)\n",
    "        TeamScores.loc[t1,t2] = Tsc/count   \n",
    "\n",
    "TeamScores.columns = ['TeamB','TeamA']\n",
    "\n",
    "TeamScores.index = ['TeamB','TeamA']\n",
    "TeamScores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team Strength og Wild Type Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(TeamScores).sum(axis = 1).sum(axis = 0)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "log = []\n",
    "dp=Topo_Network_5\n",
    "\n",
    "\n",
    "for oi in range(100):\n",
    "    edges = list(dp['Type'])\n",
    "    random.shuffle(edges)\n",
    "    dp['Type'] = edges\n",
    "\n",
    "    n=len(set(dp['Source']))\n",
    "    adj = pd.DataFrame([[0]*n]*n)\n",
    "    adj.columns=set(dp.loc[:,'Source'])\n",
    "    adj.index=set(dp.loc[:,'Source'])\n",
    "    \n",
    "    for i in range(len(dp)):\n",
    "        if dp.iloc[i,2] == 1:\n",
    "            adj.loc[dp.iloc[i,0] , dp.iloc[i,1] ] = 1\n",
    "        elif dp.iloc[i,2] == 2:\n",
    "            adj.loc[dp.iloc[i,0] , dp.iloc[i,1] ] = -1\n",
    "\n",
    "\n",
    "    n=len(set(dp['Source']))\n",
    "    infl = pd.DataFrame([[0]*n]*n)\n",
    "    infl.columns=set(dp.loc[:,'Source'])\n",
    "    infl.index=set(dp.loc[:,'Source'])\n",
    "    \n",
    "    maxi = abs(adj)\n",
    "    pr = adj\n",
    "    mr = abs(adj)\n",
    "    infl = adj\n",
    "    for i in range(1, 8):\n",
    "        pr=adj@pr\n",
    "        mr = maxi@mr\n",
    "        qwe = pr/mr\n",
    "\n",
    "        infl = infl + qwe.replace(np.nan, 0)\n",
    "        \n",
    "    infl  = infl/8\n",
    "    infl\n",
    "\n",
    "\n",
    "    Team1 = []\n",
    "    Team2 = []\n",
    "\n",
    "    for i in infl.index:\n",
    "        if infl.loc[i,'miR200'] >= 0:\n",
    "            Team1.append(i)\n",
    "        elif infl.loc[i,'miR200'] <= 0:\n",
    "            Team2.append(i) \n",
    "    \n",
    "\n",
    "    TeamScores = pd.DataFrame(0, columns = [0,1], index = [0,1] )\n",
    "\n",
    "    teams = [Team1, Team2]\n",
    "\n",
    "    for t1 in range(len(teams)):\n",
    "        for t2 in range(len(teams)):\n",
    "            Tsc= 0 \n",
    "            count = 1\n",
    "            #print(teams[t1])\n",
    "            for i in teams[t1]:\n",
    "                for j in teams[t2]:\n",
    "                    Tsc += infl.loc[i,j]\n",
    "                    count +=1\n",
    "                    #print(t1,t2)\n",
    "            TeamScores.loc[t1,t2] = Tsc/count   \n",
    "\n",
    "    TeamScores.columns = ['TeamB','TeamA']\n",
    "\n",
    "    TeamScores.index = ['TeamB','TeamA']\n",
    "    TeamScores\n",
    "    \n",
    "    log.append(abs(TeamScores).sum(axis = 1).sum(axis = 0)/4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qwer = pd.DataFrame(log)\n",
    "qwer[1]= qwer.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=qwer, x = 0,stat = \"probability\", bins = 50,palette=\"tab10\",element=\"step\")\n",
    "plt.axvline(x = 0.37318735827664407, color = 'r', linestyle = '-')\n",
    "plt.xlabel('Team Strength')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "log = []\n",
    "dp=Topo_Network_5\n",
    "\n",
    "\n",
    "for oi in range(1000):\n",
    "    edges = list(dp['Type'])\n",
    "    random.shuffle(edges)\n",
    "    dp['Type'] = edges\n",
    "\n",
    "    n=len(set(dp['Source']))\n",
    "    adj = pd.DataFrame([[0]*n]*n)\n",
    "    adj.columns=set(dp.loc[:,'Source'])\n",
    "    adj.index=set(dp.loc[:,'Source'])\n",
    "    \n",
    "    for i in range(len(dp)):\n",
    "        if dp.iloc[i,2] == 1:\n",
    "            adj.loc[dp.iloc[i,0] , dp.iloc[i,1] ] = 1\n",
    "        elif dp.iloc[i,2] == 2:\n",
    "            adj.loc[dp.iloc[i,0] , dp.iloc[i,1] ] = -1\n",
    "\n",
    "\n",
    "    n=len(set(dp['Source']))\n",
    "    infl = pd.DataFrame([[0]*n]*n)\n",
    "    infl.columns=set(dp.loc[:,'Source'])\n",
    "    infl.index=set(dp.loc[:,'Source'])\n",
    "    \n",
    "    maxi = abs(adj)\n",
    "    pr = adj\n",
    "    mr = abs(adj)\n",
    "    infl = adj\n",
    "    for i in range(1, 8):\n",
    "        pr=adj@pr\n",
    "        mr = maxi@mr\n",
    "        qwe = pr/mr\n",
    "\n",
    "        infl = infl + qwe.replace(np.nan, 0)\n",
    "        \n",
    "    infl  = infl/8\n",
    "    infl\n",
    "\n",
    "\n",
    "    Team1 = []\n",
    "    Team2 = []\n",
    "\n",
    "    for i in infl.index:\n",
    "        if infl.loc[i,'miR200'] >= 0:\n",
    "            Team1.append(i)\n",
    "        elif infl.loc[i,'miR200'] <= 0:\n",
    "            Team2.append(i) \n",
    "    \n",
    "\n",
    "    TeamScores = pd.DataFrame(0, columns = [0,1], index = [0,1] )\n",
    "\n",
    "    teams = [Team1, Team2]\n",
    "\n",
    "    for t1 in range(len(teams)):\n",
    "        for t2 in range(len(teams)):\n",
    "            Tsc= 0 \n",
    "            count = 1\n",
    "            #print(teams[t1])\n",
    "            for i in teams[t1]:\n",
    "                for j in teams[t2]:\n",
    "                    Tsc += infl.loc[i,j]\n",
    "                    count +=1\n",
    "                    #print(t1,t2)\n",
    "            TeamScores.loc[t1,t2] = Tsc/count   \n",
    "\n",
    "    TeamScores.columns = ['TeamB','TeamA']\n",
    "\n",
    "    TeamScores.index = ['TeamB','TeamA']\n",
    "    TeamScores\n",
    "    \n",
    "    log.append(abs(TeamScores).sum(axis = 1).sum(axis = 0)/4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qwer = pd.DataFrame(log)\n",
    "qwer[1]= qwer.index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi']= 1000\n",
    "sns.histplot(data=qwer, x = 0,stat = \"probability\", bins = 50,palette=\"tab10\",element=\"step\")\n",
    "plt.axvline(x = 0.37318735827664407, color = 'r', linestyle = '-', label = 'WT'+'TS='+str(0.286))\n",
    "plt.text(0.352, 0.025, 'Team Strength ( WT Network )', size='12', color='Red', rotation=90)\n",
    "plt.xlabel('Team Strength', fontweight='bold', fontsize='15' , fontname='Arial')\n",
    "plt.ylabel('Frequency', fontweight='bold', fontsize='15' , fontname='Arial')\n",
    "plt.xticks( fontsize='13')\n",
    "plt.yticks( fontsize='13')\n",
    "\n",
    "\n",
    "\n",
    "#plt.figure(figsize=(30,20))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d47d9269cffa2cf13049e19e7e2c2cdbc3e0a106bf3d85d87066843337b02bbd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
